{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "962a37b7-f27a-445d-8426-f0ff480a82a9",
   "metadata": {},
   "source": [
    "# Modeling Absenteeism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1067d-4925-471c-9a43-34d3d95ddbad",
   "metadata": {},
   "source": [
    "## Simple Binary choice model: Probit or Logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fe54a5-b844-4073-91d6-b24fbe9e58cb",
   "metadata": {},
   "source": [
    "### Model specification:\n",
    "We can specify our model as a binary outcome where \n",
    "\n",
    "$$\n",
    "y_i = \\begin{cases}\n",
    "   1 &\\text{if } \\text{student } i \\text{ is absent} \\\\\n",
    "   0 &\\text{if } \\text{if student } i \\text{ is present}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Our basic model could be:\n",
    "\n",
    "$y_i = X_iB + u_i$\n",
    "\n",
    "where $X_i$ is the vector of independent variables (e.g. student age, grade, school characteristics) and $B$ are the coefficients we want to estimate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e81ff6c-977f-4df9-b01d-901502627253",
   "metadata": {},
   "source": [
    "### Estimation:\n",
    "We will use maximum likelihood estimation to find the value for $B$ that maximize the probability of observing the $y_i$ given our independent variables.\n",
    "The Probit model uses a cumulative normal distribution function $F(x)$ to model the probability that $y_i = 1$, i.e.\n",
    "\n",
    "$$\n",
    "P(y_i = 1 | X_i, B) = F(X_iB)\n",
    "$$\n",
    "\n",
    "where $F$ is the standard normal cdf.\n",
    "\n",
    "The Logit model uses a logistic function instead of a normal cdf, i.e.\n",
    "\n",
    "$$\n",
    "P(y_i = 1 | X_i, B) = exp(X_iB) / (1 + exp(X_iB))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a9fa85-6d92-4be7-8825-2283dcdcba22",
   "metadata": {},
   "source": [
    "### Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d98d5d-995c-45ac-9cda-453cfc81215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Coefficients: [ 0.5  0.3 -0.2  0.1]\n",
      "Estimated Coefficients: [ 0.61650116  0.28666403 -0.25712836  0.05877295]\n",
      "Number of samples: 1000\n",
      "Number of 0s: 351\n",
      "Number of 1s: 649\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import optimize\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the number of observations and the number of independent variables\n",
    "n_observations = 1000\n",
    "n_independent_variables = 3\n",
    "\n",
    "# Generate random data for the independent variables\n",
    "X = np.random.randn(n_observations, n_independent_variables)\n",
    "\n",
    "# Generate true coefficients (including intercept)\n",
    "true_B = np.array([0.5, 0.3, -0.2, 0.1])  # Intercept and three coefficients\n",
    "\n",
    "# Add intercept term\n",
    "X_with_intercept = np.column_stack((np.ones(n_observations), X))\n",
    "\n",
    "# Compute linear predictor\n",
    "z = np.dot(X_with_intercept, true_B)\n",
    "\n",
    "# Compute probabilities\n",
    "p = 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Generate binary outcomes with correct probability\n",
    "y = (np.random.rand(n_observations) < p).astype(int)\n",
    "\n",
    "def log_likelihood(B, X, y):\n",
    "    # Compute probabilities\n",
    "    z = np.dot(X, B)\n",
    "    p = 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    # Avoid log(0) with small epsilon\n",
    "    eps = 1e-15\n",
    "    p = np.clip(p, eps, 1 - eps)\n",
    "    \n",
    "    # Compute log-likelihood\n",
    "    ll = np.sum(y * np.log(p) + (1 - y) * np.log(1 - p))\n",
    "    \n",
    "    return -ll\n",
    "\n",
    "# Initial guess for coefficients\n",
    "B_init = np.zeros(n_independent_variables + 1)\n",
    "\n",
    "# Optimize log-likelihood\n",
    "result = optimize.minimize(log_likelihood, B_init, args=(X_with_intercept, y), method='BFGS')\n",
    "\n",
    "# Save results\n",
    "data = pd.DataFrame(np.column_stack((y, X)), columns=[\"y\", \"x1\", \"x2\", \"x3\"])\n",
    "data.to_csv(\"logistic_regression_data.csv\", index=False)\n",
    "\n",
    "print(\"True Coefficients:\", true_B)\n",
    "print(\"Estimated Coefficients:\", result.x)\n",
    "print(\"Number of samples:\", len(y))\n",
    "print(\"Number of 0s:\", np.sum(y == 0))\n",
    "print(\"Number of 1s:\", np.sum(y == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f6573-bace-421d-9848-43e8fd4a6c54",
   "metadata": {},
   "source": [
    "### Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01adfdd9-2c05-4435-ae46-b3cf73a64543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.270569\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 1000\n",
      "Model:                          Logit   Df Residuals:                      996\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 28 Nov 2024   Pseudo R-squ.:                  0.5910\n",
      "Time:                        18:06:54   Log-Likelihood:                -270.57\n",
      "converged:                       True   LL-Null:                       -661.56\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.488e-169\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.2154      0.127     -9.556      0.000      -1.465      -0.966\n",
      "age           -2.0019      0.171    -11.719      0.000      -2.337      -1.667\n",
      "grade         -0.1109      0.111     -0.998      0.318      -0.329       0.107\n",
      "school        -3.5513      0.244    -14.553      0.000      -4.030      -3.073\n",
      "==============================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.269011\n",
      "         Iterations 8\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 1000\n",
      "Model:                         Probit   Df Residuals:                      996\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 28 Nov 2024   Pseudo R-squ.:                  0.5934\n",
      "Time:                        18:06:54   Log-Likelihood:                -269.01\n",
      "converged:                       True   LL-Null:                       -661.56\n",
      "Covariance Type:            nonrobust   LLR p-value:                7.356e-170\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.6787      0.069     -9.904      0.000      -0.813      -0.544\n",
      "age           -1.1382      0.091    -12.503      0.000      -1.317      -0.960\n",
      "grade         -0.0639      0.063     -1.018      0.309      -0.187       0.059\n",
      "school        -2.0243      0.128    -15.836      0.000      -2.275      -1.774\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.13 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.discrete.discrete_model import Logit, Probit\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"data/absence_data.csv\")\n",
    "\n",
    "# Prepare predictors and target\n",
    "X = data[[\"age\", \"grade\", \"school\"]]\n",
    "X = sm.add_constant(X)  # Add constant term for intercept\n",
    "y = data[\"y\"]\n",
    "\n",
    "# Logit Model\n",
    "logit_model = Logit(y, X).fit()\n",
    "print(logit_model.summary())\n",
    "\n",
    "# Probit Model\n",
    "probit_model = Probit(y, X).fit()\n",
    "print(probit_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788e8e56-98b4-4c93-ac23-2a780fc82779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
